{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hex-level GridScore data prep\n",
    "\n",
    "Goal: build a merged dataframe that attaches region-level GridScore components to each hex cell and keeps the per-hex climate/terrain fields (temp, elevation). We'll reuse existing CSVs only:\n",
    "\n",
    "- `datacenter_scores_real.csv`: region-level metrics (profitability, sustainability, dc_score, and raw/normalized inputs)\n",
    "- `hex_weather_data_all.csv`: per-hex climate/terrain (hex_id, local_temp_c, elevation_m)\n",
    "- Optionally, we can bring in precomputed fields from the existing map JSON if needed later.\n",
    "\n",
    "**This notebook stops at the merged dataframe**; no JSON/GeoJSON export yet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "068a4e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = Path('.')\n",
    "SCORES_PATH = DATA_DIR / 'datacenter_scores_real.csv'\n",
    "HEX_CLIMATE_PATH = DATA_DIR / 'hex_weather_data_all.csv'\n",
    "\n",
    "assert SCORES_PATH.exists(), 'datacenter_scores_real.csv not found'\n",
    "assert HEX_CLIMATE_PATH.exists(), 'hex_weather_data_all.csv not found'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218854cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  region   lat    lon  raw_price  raw_load  raw_volatility  raw_peak  \\\n",
       " 0     NY  42.9  -75.3    47.0075   18803.0      651.338754   20325.0   \n",
       " 1    CAR  35.5  -80.0    55.9950   22398.0      688.416472   35825.0   \n",
       " 2    TEN  36.0  -86.0    44.8175   17927.0      417.266953   26174.0   \n",
       " 3     NW  45.5 -120.5   114.7850   45914.0     2068.570205   49728.0   \n",
       " 4     NE  42.5  -72.5    38.5175   15407.0      640.962908   16897.0   \n",
       " \n",
       "    raw_renew   raw_temp   n_price    n_load  n_volatility    n_temp   n_renew  \\\n",
       " 0  51.350038   5.800000  0.919927  0.919927      0.936484  1.000000  0.804842   \n",
       " 1  60.187159  13.795522  0.877463  0.877463      0.926423  0.483513  1.000000   \n",
       " 2  50.679782  13.898507  0.930274  0.930274      1.000000  0.476861  0.790040   \n",
       " 3  55.439846   8.534328  0.599693  0.599693      0.551913  0.823371  0.895161   \n",
       " 4  32.106455   7.720896  0.960040  0.960040      0.939299  0.875916  0.379869   \n",
       " \n",
       "    profitability  sustainability  dc_score  \n",
       " 0       0.924894        0.863389  0.887991  \n",
       " 1       0.892151        0.845054  0.863893  \n",
       " 2       0.951192        0.696086  0.798129  \n",
       " 3       0.585359        0.873624  0.758318  \n",
       " 4       0.953818        0.528683  0.698737  ,\n",
       "    hex_id  local_temp_c  elevation_m\n",
       " 0       0     27.067568        104.0\n",
       " 1       1     26.656757         12.0\n",
       " 2       2     27.183784         77.0\n",
       " 3       3     23.048649        477.0\n",
       " 4       4     25.024324        118.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick peek at the inputs\n",
    "scores_df = pd.read_csv(SCORES_PATH)\n",
    "hex_df = pd.read_csv(HEX_CLIMATE_PATH)\n",
    "\n",
    "scores_df.head(), hex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80ed3597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores columns: ['region', 'lat', 'lon', 'raw_price', 'raw_load', 'raw_volatility', 'raw_peak', 'raw_renew', 'raw_temp', 'n_price', 'n_load', 'n_volatility', 'n_temp', 'n_renew', 'profitability', 'sustainability', 'dc_score']\n",
      "Hex columns: ['hex_id', 'local_temp_c', 'elevation_m']\n",
      "\n",
      "Counts: scores 13 hexes 1723\n"
     ]
    }
   ],
   "source": [
    "# Columns overview\n",
    "print('Scores columns:', scores_df.columns.tolist())\n",
    "print('Hex columns:', hex_df.columns.tolist())\n",
    "print('\\nCounts: scores', len(scores_df), 'hexes', len(hex_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4d6b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean column names (already snake_case but enforce consistency)\n",
    "score_cols = [c.strip() for c in scores_df.columns]\n",
    "hex_cols = [c.strip() for c in hex_df.columns]\n",
    "\n",
    "scores_df.columns = score_cols\n",
    "hex_df.columns = hex_cols\n",
    "\n",
    "# Ensure key columns exist\n",
    "required_scores = {'region', 'lat', 'lon', 'profitability', 'sustainability', 'dc_score'}\n",
    "required_hex = {'hex_id', 'local_temp_c', 'elevation_m'}\n",
    "missing_scores = required_scores - set(scores_df.columns)\n",
    "missing_hex = required_hex - set(hex_df.columns)\n",
    "assert not missing_scores, f\"Missing in scores: {missing_scores}\"\n",
    "assert not missing_hex, f\"Missing in hex: {missing_hex}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a38fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy for attaching region metrics to hexes:\n",
    "# - We don't have an explicit region field per hex in the climate file.\n",
    "# - The original folium map used nearest region centroids / dist_to_region.\n",
    "# - We'll assign each hex to the nearest region centroid using haversine distance.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def haversine_vec(lat1, lon1, lat2, lon2):\n",
    "    # lat/lon in degrees, returns meters\n",
    "    R = 6371000.0\n",
    "    phi1 = np.radians(lat1)\n",
    "    phi2 = np.radians(lat2)\n",
    "    dphi = np.radians(lat2 - lat1)\n",
    "    dlambda = np.radians(lon2 - lon1)\n",
    "    a = np.sin(dphi / 2.0) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(dlambda / 2.0) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# Prepare region centroids\n",
    "region_centroids = scores_df[['region', 'lat', 'lon']].copy().rename(columns={'lat': 'region_lat', 'lon': 'region_lon'})\n",
    "\n",
    "hex_coords = hex_df[['hex_id']].copy()\n",
    "\n",
    "# If hex lat/lon are available in the map JSON, we could import them; for now, approximate using region lat/lon from the CSVs if present in hex_df\n",
    "# (the provided hex_weather_data_all.csv only has temp/elevation). We'll require lat/lon per hex later when exporting GeoJSON.\n",
    "\n",
    "# Placeholder: if hex_df already has lat/lon columns, keep them\n",
    "for candidate in ['lat', 'lon']:\n",
    "    if candidate in hex_df.columns:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "851b2b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found hex lat/lon rows from map JSON: 1723\n",
      "Hex rows missing coords after merge: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_id</th>\n",
       "      <th>local_temp_c</th>\n",
       "      <th>elevation_m</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>region</th>\n",
       "      <th>dist_to_region_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27.067568</td>\n",
       "      <td>104.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>FLA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26.656757</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>FLA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>27.183784</td>\n",
       "      <td>77.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>FLA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23.048649</td>\n",
       "      <td>477.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>FLA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>25.024324</td>\n",
       "      <td>118.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>FLA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hex_id  local_temp_c  elevation_m   lat   lon region  dist_to_region_m\n",
       "0       0     27.067568        104.0  28.0 -82.0    FLA               0.0\n",
       "1       1     26.656757         12.0  28.0 -82.0    FLA               0.0\n",
       "2       2     27.183784         77.0  28.0 -82.0    FLA               0.0\n",
       "3       3     23.048649        477.0  28.0 -82.0    FLA               0.0\n",
       "4       4     25.024324        118.0  28.0 -82.0    FLA               0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a minimal merge now, map each hex to nearest region centroid.\n",
    "# In the absence of hex lat/lon in hex_weather_data_all.csv, we cannot compute distances here.\n",
    "# However, the existing score_map.json already includes lat/lon per hex. We'll read it to attach hex coordinates for distance mapping.\n",
    "\n",
    "SCORE_MAP_JSON = Path('public/data/score_map.json')\n",
    "assert SCORE_MAP_JSON.exists(), 'public/data/score_map.json not found (needed for hex lat/lon)'\n",
    "\n",
    "with SCORE_MAP_JSON.open() as f:\n",
    "    fc = json.load(f)\n",
    "\n",
    "map_features = fc.get('features', [])\n",
    "hex_lat_lon = []\n",
    "for feat in map_features:\n",
    "    props = feat.get('properties', {})\n",
    "    hex_id = props.get('hex_id')\n",
    "    lat = props.get('lat')\n",
    "    lon = props.get('lon')\n",
    "    if hex_id is not None and lat is not None and lon is not None:\n",
    "        hex_lat_lon.append({'hex_id': hex_id, 'lat': lat, 'lon': lon})\n",
    "\n",
    "hex_latlon_df = pd.DataFrame(hex_lat_lon).drop_duplicates(subset='hex_id')\n",
    "print('Found hex lat/lon rows from map JSON:', len(hex_latlon_df))\n",
    "\n",
    "# Merge lat/lon into hex climate df\n",
    "hex_df = hex_df.merge(hex_latlon_df, on='hex_id', how='left')\n",
    "missing_coords = hex_df['lat'].isna().sum()\n",
    "print('Hex rows missing coords after merge:', missing_coords)\n",
    "\n",
    "# Assign nearest region\n",
    "regions_np = region_centroids[['region', 'region_lat', 'region_lon']].to_numpy()\n",
    "hex_region = []\n",
    "for _, row in hex_df.iterrows():\n",
    "    lat = row['lat']\n",
    "    lon = row['lon']\n",
    "    if pd.isna(lat) or pd.isna(lon):\n",
    "        hex_region.append({'region': None, 'dist_to_region_m': None})\n",
    "        continue\n",
    "    dists = haversine_vec(lat, lon, regions_np[:,1].astype(float), regions_np[:,2].astype(float))\n",
    "    idx = np.argmin(dists)\n",
    "    hex_region.append({'region': regions_np[idx,0], 'dist_to_region_m': float(dists[idx])})\n",
    "\n",
    "hex_region_df = pd.DataFrame(hex_region)\n",
    "hex_df = pd.concat([hex_df.reset_index(drop=True), hex_region_df], axis=1)\n",
    "\n",
    "hex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3092473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged rows: 1723\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_id</th>\n",
       "      <th>local_temp_c</th>\n",
       "      <th>elevation_m</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>region</th>\n",
       "      <th>dist_to_region_m</th>\n",
       "      <th>lat_region</th>\n",
       "      <th>lon_region</th>\n",
       "      <th>raw_price</th>\n",
       "      <th>...</th>\n",
       "      <th>raw_renew</th>\n",
       "      <th>raw_temp</th>\n",
       "      <th>n_price</th>\n",
       "      <th>n_load</th>\n",
       "      <th>n_volatility</th>\n",
       "      <th>n_temp</th>\n",
       "      <th>n_renew</th>\n",
       "      <th>profitability</th>\n",
       "      <th>sustainability</th>\n",
       "      <th>dc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27.067568</td>\n",
       "      <td>104.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>FLA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>84.0725</td>\n",
       "      <td>...</td>\n",
       "      <td>14.905253</td>\n",
       "      <td>21.280597</td>\n",
       "      <td>0.744803</td>\n",
       "      <td>0.744803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26.656757</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>FLA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>84.0725</td>\n",
       "      <td>...</td>\n",
       "      <td>14.905253</td>\n",
       "      <td>21.280597</td>\n",
       "      <td>0.744803</td>\n",
       "      <td>0.744803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>27.183784</td>\n",
       "      <td>77.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>FLA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>84.0725</td>\n",
       "      <td>...</td>\n",
       "      <td>14.905253</td>\n",
       "      <td>21.280597</td>\n",
       "      <td>0.744803</td>\n",
       "      <td>0.744803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23.048649</td>\n",
       "      <td>477.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>FLA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>84.0725</td>\n",
       "      <td>...</td>\n",
       "      <td>14.905253</td>\n",
       "      <td>21.280597</td>\n",
       "      <td>0.744803</td>\n",
       "      <td>0.744803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>25.024324</td>\n",
       "      <td>118.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>FLA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>84.0725</td>\n",
       "      <td>...</td>\n",
       "      <td>14.905253</td>\n",
       "      <td>21.280597</td>\n",
       "      <td>0.744803</td>\n",
       "      <td>0.744803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hex_id  local_temp_c  elevation_m   lat   lon region  dist_to_region_m  \\\n",
       "0       0     27.067568        104.0  28.0 -82.0    FLA               0.0   \n",
       "1       1     26.656757         12.0  28.0 -82.0    FLA               0.0   \n",
       "2       2     27.183784         77.0  28.0 -82.0    FLA               0.0   \n",
       "3       3     23.048649        477.0  28.0 -82.0    FLA               0.0   \n",
       "4       4     25.024324        118.0  28.0 -82.0    FLA               0.0   \n",
       "\n",
       "   lat_region  lon_region  raw_price  ...  raw_renew   raw_temp   n_price  \\\n",
       "0        28.0       -82.0    84.0725  ...  14.905253  21.280597  0.744803   \n",
       "1        28.0       -82.0    84.0725  ...  14.905253  21.280597  0.744803   \n",
       "2        28.0       -82.0    84.0725  ...  14.905253  21.280597  0.744803   \n",
       "3        28.0       -82.0    84.0725  ...  14.905253  21.280597  0.744803   \n",
       "4        28.0       -82.0    84.0725  ...  14.905253  21.280597  0.744803   \n",
       "\n",
       "     n_load  n_volatility  n_temp  n_renew  profitability  sustainability  \\\n",
       "0  0.744803           0.0     0.0      0.0       0.521362             0.0   \n",
       "1  0.744803           0.0     0.0      0.0       0.521362             0.0   \n",
       "2  0.744803           0.0     0.0      0.0       0.521362             0.0   \n",
       "3  0.744803           0.0     0.0      0.0       0.521362             0.0   \n",
       "4  0.744803           0.0     0.0      0.0       0.521362             0.0   \n",
       "\n",
       "   dc_score  \n",
       "0  0.208545  \n",
       "1  0.208545  \n",
       "2  0.208545  \n",
       "3  0.208545  \n",
       "4  0.208545  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join region metrics onto each hex using the assigned region\n",
    "merged = hex_df.merge(scores_df, on='region', how='left', suffixes=('', '_region'))\n",
    "\n",
    "# Use the merged frame as the working hex_df for downstream scoring\n",
    "hex_df = merged.copy()\n",
    "\n",
    "print('Merged rows:', len(hex_df))\n",
    "hex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3fcb064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls per important column:\n",
      "hex_id              0\n",
      "region              0\n",
      "profitability       0\n",
      "sustainability      0\n",
      "dc_score            0\n",
      "local_temp_c        0\n",
      "elevation_m         0\n",
      "lat                 0\n",
      "lon                 0\n",
      "dist_to_region_m    0\n",
      "dtype: int64\n",
      "\n",
      "Describe:\n",
      "          dc_score  profitability  sustainability  local_temp_c  elevation_m  \\\n",
      "count  1723.000000    1723.000000     1723.000000   1723.000000  1723.000000   \n",
      "mean      0.584993       0.637101        0.550254      5.415026   658.091120   \n",
      "std       0.200023       0.225168        0.273227      8.618531   688.405905   \n",
      "min       0.208545       0.195956        0.000000    -19.437838   -57.000000   \n",
      "25%       0.456543       0.585359        0.367141      1.222973   145.500000   \n",
      "50%       0.656931       0.585359        0.450939      5.637838   373.000000   \n",
      "75%       0.758318       0.826845        0.873624     11.290541  1037.000000   \n",
      "max       0.887991       0.965919        0.873624     27.362162  3890.000000   \n",
      "\n",
      "       dist_to_region_m  \n",
      "count            1723.0  \n",
      "mean                0.0  \n",
      "std                 0.0  \n",
      "min                 0.0  \n",
      "25%                 0.0  \n",
      "50%                 0.0  \n",
      "75%                 0.0  \n",
      "max                 0.0  \n"
     ]
    }
   ],
   "source": [
    "# Basic sanity checks\n",
    "print('Nulls per important column:')\n",
    "print(merged[['hex_id','region','profitability','sustainability','dc_score','local_temp_c','elevation_m','lat','lon','dist_to_region_m']].isna().sum())\n",
    "\n",
    "# Quick descriptive stats for per-hex fields we care about\n",
    "summary_cols = ['dc_score','profitability','sustainability','local_temp_c','elevation_m','dist_to_region_m']\n",
    "print('\\nDescribe:')\n",
    "print(merged[summary_cols].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7445fd",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Design per-hex adjustments (temperature/elevation tweaks) to create a unique `dc_score` per hex.\n",
    "- Compute `dc_score_temp`/`temp_cool_score` analogs.\n",
    "- Export FeatureCollection/JSON when ready (not done here)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d67082f",
   "metadata": {},
   "source": [
    "## Per-hex scoring function\n",
    "Approach:\n",
    "- Base scores: region profitability/sustainability (already 60/40 combined)\n",
    "- Temp bonus: cooler hexes get higher `temp_cool_score` (1 - normalized temp)\n",
    "- Elevation bonus: higher elevation -> slight cooling proxy (normalized)\n",
    "- Adjust sustainability with temp/elevation micro-weights; leave profitability mostly region-driven (can add small temp effect if desired)\n",
    "- Optional spatial smoothing: k-NN average to reduce abrupt jumps (kept small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60389d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_id</th>\n",
       "      <th>region</th>\n",
       "      <th>profitability</th>\n",
       "      <th>profitability_hex</th>\n",
       "      <th>sustainability</th>\n",
       "      <th>sustainability_hex</th>\n",
       "      <th>dc_score</th>\n",
       "      <th>dc_score_hex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FLA</td>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.208545</td>\n",
       "      <td>0.209481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLA</td>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.208545</td>\n",
       "      <td>0.208653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FLA</td>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.208545</td>\n",
       "      <td>0.209238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>FLA</td>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>0.208545</td>\n",
       "      <td>0.212838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>FLA</td>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.208545</td>\n",
       "      <td>0.209607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hex_id region  profitability  profitability_hex  sustainability  \\\n",
       "0       0    FLA       0.521362           0.521362             0.0   \n",
       "1       1    FLA       0.521362           0.521362             0.0   \n",
       "2       2    FLA       0.521362           0.521362             0.0   \n",
       "3       3    FLA       0.521362           0.521362             0.0   \n",
       "4       4    FLA       0.521362           0.521362             0.0   \n",
       "\n",
       "   sustainability_hex  dc_score  dc_score_hex  \n",
       "0            0.001560  0.208545      0.209481  \n",
       "1            0.000180  0.208545      0.208653  \n",
       "2            0.001155  0.208545      0.209238  \n",
       "3            0.007156  0.208545      0.212838  \n",
       "4            0.001770  0.208545      0.209607  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minmax_clamped(series, lower_q=0.01, upper_q=0.99):\n",
    "    lo, hi = series.quantile(lower_q), series.quantile(upper_q)\n",
    "    rng = hi - lo if hi > lo else 1\n",
    "    return ((series.clip(lo, hi) - lo) / rng).fillna(0.5)\n",
    "\n",
    "# Normalized climate signals (0-1)\n",
    "hex_df['temp_norm'] = minmax_clamped(hex_df['local_temp_c'])\n",
    "hex_df['temp_cool_score'] = 1 - hex_df['temp_norm']  # cooler is better\n",
    "hex_df['elev_norm'] = minmax_clamped(hex_df['elevation_m'])\n",
    "\n",
    "# Micro-weights tuned for smoother transitions\n",
    "TEMP_WEIGHT = 0.15  # contributes to sustainability\n",
    "ELEV_WEIGHT = 0.05  # smaller effect\n",
    "SMOOTH_K = 20       # neighbors for smoothing\n",
    "SMOOTH_BLEND = 0.25 # self vs neighbor blend\n",
    "\n",
    "# Adjust sustainability using climate signals\n",
    "hex_df['sustainability_hex'] = (\n",
    "    hex_df['sustainability']\n",
    "    + hex_df['temp_cool_score'] * TEMP_WEIGHT\n",
    "    + hex_df['elev_norm'] * ELEV_WEIGHT\n",
    ")\n",
    "\n",
    "# Profitability mostly region-level; leave as-is (optional: add tiny temp effect)\n",
    "hex_df['profitability_hex'] = hex_df['profitability']\n",
    "\n",
    "# Recombine to per-hex dc_score (60/40 weighting)\n",
    "hex_df['dc_score_hex'] = 0.6 * hex_df['sustainability_hex'] + 0.4 * hex_df['profitability_hex']\n",
    "\n",
    "hex_df[['hex_id','region','profitability','profitability_hex','sustainability','sustainability_hex','dc_score','dc_score_hex']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb0f9287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dc_score_hex</th>\n",
       "      <th>dc_score_hex_smooth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1723.000000</td>\n",
       "      <td>1723.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.612440</td>\n",
       "      <td>0.611642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.206227</td>\n",
       "      <td>0.205394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.208563</td>\n",
       "      <td>0.209174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.464125</td>\n",
       "      <td>0.467766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.690525</td>\n",
       "      <td>0.690329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.795057</td>\n",
       "      <td>0.792709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.921598</td>\n",
       "      <td>0.920189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dc_score_hex  dc_score_hex_smooth\n",
       "count   1723.000000          1723.000000\n",
       "mean       0.612440             0.611642\n",
       "std        0.206227             0.205394\n",
       "min        0.208563             0.209174\n",
       "25%        0.464125             0.467766\n",
       "50%        0.690525             0.690329\n",
       "75%        0.795057             0.792709\n",
       "max        0.921598             0.920189"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional spatial smoothing for dc_score_hex\n",
    "import numpy as np\n",
    "\n",
    "coords = hex_df[['lat','lon']].to_numpy()\n",
    "scores_arr = hex_df['dc_score_hex'].to_numpy()\n",
    "\n",
    "def knn_smooth(coords, values, k=6, self_weight=0.7):\n",
    "    smoothed = np.array(values, copy=True)\n",
    "    valid = ~np.isnan(coords).any(axis=1)\n",
    "    if valid.sum() < 2:\n",
    "        return smoothed\n",
    "    k_eff = max(1, min(k, valid.sum() - 1))\n",
    "    coords_v = coords[valid]\n",
    "    vals_v = values[valid]\n",
    "\n",
    "    # haversine distances for smoother spatial blending\n",
    "    lat = np.radians(coords_v[:,0])[:,None]\n",
    "    lon = np.radians(coords_v[:,1])[:,None]\n",
    "    lat_T = lat.T\n",
    "    lon_T = lon.T\n",
    "    dphi = lat - lat_T\n",
    "    dlambda = lon - lon_T\n",
    "    a = np.sin(dphi/2.0)**2 + np.cos(lat)*np.cos(lat_T)*np.sin(dlambda/2.0)**2\n",
    "    dist = 2 * 6371000 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    np.fill_diagonal(dist, np.inf)\n",
    "\n",
    "    knn_idx = np.argpartition(dist, kth=k_eff-1, axis=1)[:, :k_eff]\n",
    "    neighbor_means = vals_v[knn_idx].mean(axis=1)\n",
    "    smoothed_v = self_weight * vals_v + (1 - self_weight) * neighbor_means\n",
    "    smoothed[valid] = smoothed_v\n",
    "    return smoothed\n",
    "\n",
    "hex_df['dc_score_hex_smooth'] = knn_smooth(coords, scores_arr, k=SMOOTH_K, self_weight=SMOOTH_BLEND)\n",
    "hex_df[['dc_score_hex','dc_score_hex_smooth']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ab4d023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          dc_score  dc_score_hex  dc_score_hex_smooth  sustainability  \\\n",
      "count  1723.000000   1723.000000          1723.000000     1723.000000   \n",
      "mean      0.584993      0.612440             0.611642        0.550254   \n",
      "std       0.200023      0.206227             0.205394        0.273227   \n",
      "min       0.208545      0.208563             0.209174        0.000000   \n",
      "25%       0.456543      0.464125             0.467766        0.367141   \n",
      "50%       0.656931      0.690525             0.690329        0.450939   \n",
      "75%       0.758318      0.795057             0.792709        0.873624   \n",
      "max       0.887991      0.921598             0.920189        0.873624   \n",
      "\n",
      "       sustainability_hex  profitability  profitability_hex  temp_cool_score  \\\n",
      "count         1723.000000    1723.000000        1723.000000      1723.000000   \n",
      "mean             0.595999       0.637101           0.637101         0.449314   \n",
      "std              0.285395       0.225168           0.225168         0.221224   \n",
      "min              0.000030       0.195956           0.195956         0.000000   \n",
      "25%              0.409613       0.585359           0.585359         0.296927   \n",
      "50%              0.513673       0.585359           0.585359         0.443460   \n",
      "75%              0.922209       0.826845           0.826845         0.557906   \n",
      "max              0.980448       0.965919           0.965919         1.000000   \n",
      "\n",
      "         elev_norm  \n",
      "count  1723.000000  \n",
      "mean      0.244987  \n",
      "std       0.251573  \n",
      "min       0.000000  \n",
      "25%       0.054571  \n",
      "50%       0.139897  \n",
      "75%       0.388937  \n",
      "max       1.000000  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_id</th>\n",
       "      <th>region</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>dc_score_hex</th>\n",
       "      <th>dc_score_hex_smooth</th>\n",
       "      <th>temp_cool_score</th>\n",
       "      <th>elev_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>182</td>\n",
       "      <td>TEX</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.237108</td>\n",
       "      <td>0.238718</td>\n",
       "      <td>0.171762</td>\n",
       "      <td>0.047633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>1391</td>\n",
       "      <td>NW</td>\n",
       "      <td>45.5</td>\n",
       "      <td>-120.5</td>\n",
       "      <td>0.781689</td>\n",
       "      <td>0.784171</td>\n",
       "      <td>0.486898</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>1401</td>\n",
       "      <td>NW</td>\n",
       "      <td>45.5</td>\n",
       "      <td>-120.5</td>\n",
       "      <td>0.795445</td>\n",
       "      <td>0.793800</td>\n",
       "      <td>0.634518</td>\n",
       "      <td>0.277919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>1716</td>\n",
       "      <td>NW</td>\n",
       "      <td>45.5</td>\n",
       "      <td>-120.5</td>\n",
       "      <td>0.803475</td>\n",
       "      <td>0.799421</td>\n",
       "      <td>0.935152</td>\n",
       "      <td>0.011252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>409</td>\n",
       "      <td>CAL</td>\n",
       "      <td>36.5</td>\n",
       "      <td>-119.5</td>\n",
       "      <td>0.470634</td>\n",
       "      <td>0.472578</td>\n",
       "      <td>0.172812</td>\n",
       "      <td>0.241539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hex_id region   lat    lon  dc_score_hex  dc_score_hex_smooth  \\\n",
       "182      182    TEX  31.0  -99.0      0.237108             0.238718   \n",
       "1391    1391     NW  45.5 -120.5      0.781689             0.784171   \n",
       "1401    1401     NW  45.5 -120.5      0.795445             0.793800   \n",
       "1716    1716     NW  45.5 -120.5      0.803475             0.799421   \n",
       "409      409    CAL  36.5 -119.5      0.470634             0.472578   \n",
       "\n",
       "      temp_cool_score  elev_norm  \n",
       "182          0.171762   0.047633  \n",
       "1391         0.486898   0.000000  \n",
       "1401         0.634518   0.277919  \n",
       "1716         0.935152   0.011252  \n",
       "409          0.172812   0.241539  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summaries to verify per-hex variation\n",
    "summary_cols = [\n",
    "    'dc_score','dc_score_hex','dc_score_hex_smooth',\n",
    "    'sustainability','sustainability_hex',\n",
    "    'profitability','profitability_hex',\n",
    "    'temp_cool_score','elev_norm',\n",
    "]\n",
    "print(hex_df[summary_cols].describe())\n",
    "\n",
    "# Inspect a few neighboring hexes (random sample)\n",
    "hex_df.sample(5)[['hex_id','region','lat','lon','dc_score_hex','dc_score_hex_smooth','temp_cool_score','elev_norm']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d985535",
   "metadata": {},
   "source": [
    "Next: export a FeatureCollection/JSON using these per-hex scores, or feed into the D3 map. (Not done here.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
